{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73a72cab",
   "metadata": {},
   "source": [
    "# Classification problems with Neural Networks in PyTorch\n",
    "    \n",
    "<a rel=\"license\" href=\"https://creativecommons.org/licenses/by/4.0/\"><img alt=\"Creative Commons Licence\" style=\"width=50\" src=\"https://licensebuttons.net/l/by/4.0/88x31.png\" title='This work is licensed under a Creative Commons Attribution 4.0 International License.' align=\"right\"/></a>\n",
    "\n",
    "**Authors**: \n",
    "- Dr Antonia Mey (antonia.mey@ed.ac.uk)\n",
    "- Katerina Karoni"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e97feb8",
   "metadata": {},
   "source": [
    "module --> package --> library --> framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba58247d",
   "metadata": {},
   "source": [
    "PyTorch is a Python framework that provides two high-level features:\n",
    "\n",
    "    Tensor computation (like NumPy) with strong GPU acceleration\n",
    "    Deep neural networks built on a autograd system\n",
    "\n",
    "You can reuse your favorite Python packages such as NumPy to extend PyTorch when needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5215a1b",
   "metadata": {},
   "source": [
    "**<h2>Pytorch Installation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0317ce5",
   "metadata": {},
   "source": [
    "To install the PyTorch binaries, you will need to use one of two supported package managers: Anaconda or pip. Anaconda is the recommended package manager as it will provide you all of the PyTorch dependencies in one, sandboxed install, including Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb2b28e",
   "metadata": {},
   "source": [
    "**Installing Anaconda** (Anaconda downloads the python interpreter/compiler as apart of the package)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec0171c",
   "metadata": {},
   "source": [
    "https://docs.anaconda.com/anaconda/install/linux/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46f601b",
   "metadata": {},
   "source": [
    "Installing torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dff5d68",
   "metadata": {},
   "source": [
    "https://pytorch.org/get-started/locally/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6bf0df",
   "metadata": {},
   "source": [
    "**<h2>Pytorch Basics**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7005c1c",
   "metadata": {},
   "source": [
    "We will look at:\n",
    "- Tensors\n",
    "- Autograd\n",
    "- Building a dataset\n",
    "- Building a neural network\n",
    "- Choosing optimiser\n",
    "- Training and testing the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc9bed8",
   "metadata": {},
   "source": [
    "Once we have installed pytorch, we can import the package like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf7db7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53553e38",
   "metadata": {},
   "source": [
    "**<h2>Tensors**\n",
    "    \n",
    "A PyTorch Tensor is basically the same as a numpy array: it does not know anything about deep learning or computational graphs or gradients, and is just a generic n-dimensional array to be used for arbitrary numeric computation.\n",
    "\n",
    "The biggest difference between a numpy array and a PyTorch Tensor is that a PyTorch Tensor can run on either CPU or GPU. To run operations on the GPU, just cast the Tensor to a cuda datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56430451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]]) \n",
      "\n",
      "Size of x =  torch.Size([2, 3]) \n",
      "\n",
      "Data type of x =  torch.float32\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[1,2,3],[4,5,6]])\n",
    "print('x =',x, '\\n')\n",
    "\n",
    "print('Size of x = ', x.size(), '\\n') # np.shape(x) also works\n",
    "\n",
    "print('Data type of x = ', x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56ea112e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]]) \n",
      "\n",
      "Data type of y =  torch.float32\n"
     ]
    }
   ],
   "source": [
    "# we can also specify data type\n",
    "\n",
    "y = torch.zeros(2,3,dtype=torch.float32) \n",
    "\n",
    "print('y =' , y, '\\n')\n",
    "\n",
    "print('Data type of y = ', y.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d271cf66",
   "metadata": {},
   "source": [
    "**Casting tensor x as cuda datatype if cuda available**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06c07389",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42b80cf",
   "metadata": {},
   "source": [
    "Attention: ```x.to(device)``` will not cast ```x```as cuda datatype - we need\n",
    "```x = x.to(device)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "100e3d99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "y = x.to(device) # or x = x.cuda() for GPU\n",
    "print(x.is_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee1ebc0",
   "metadata": {},
   "source": [
    "Note: For tensors ```x.to(device)```, as mentioned does not move ```x``` to cuda and we need to write ```x = x.to(device)``` instead.\n",
    "\n",
    "However, for neural networks, ```net.to(device)``` and\n",
    "```net = net.to(device)``` are equivalent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6f5254",
   "metadata": {},
   "source": [
    "**Tensor Data types**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad495d27",
   "metadata": {},
   "source": [
    "```DoubleTensor``` is ```64-bit``` floating point and ```FloatTensor``` is ```32-bit``` floating point tensor. So a ```FloatTensor``` uses half of the memory as a same tensor-size ```DoubleTensor``` uses. Also GPU and CPU computations with lower precision are much faster.  However, if high precision is needed, go for ```DoubleTensor``` . So Pytorch leaves it to user to choose which one to use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd5458a",
   "metadata": {},
   "source": [
    "Set default tensor type for your notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "009acf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type('torch.FloatTensor')    # 32 bits\n",
    "#or\n",
    "torch.set_default_tensor_type('torch.DoubleTensor')    # 64 bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1576f635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "torch.float64\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(2,3) \n",
    "print(x)\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20cd610",
   "metadata": {},
   "source": [
    "**<h2> Autograd**\n",
    "    \n",
    "    https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9059a9",
   "metadata": {},
   "source": [
    "```torch.autograd``` is the automatic differentiation package in pytorch - it is PyTorch’s automatic differentiation engine that powers neural network training.  Using autograd on a tensor, requires minimal changes to our code - we just need to add the keyword ```requires_grad=True```. For example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75529460",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([1., 5.],requires_grad=True) # float tensor\n",
    "b = torch.tensor([3., 6.],requires_grad=True) # tensor needs to be floating point to \n",
    "                                              # set requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873e8d66",
   "metadata": {},
   "source": [
    "*Note*: ```torch.tensor``` is different to ```torch.Tensor``` - the former infers the dtype automatically from the input, e.g. ```[1., 5.]``` vs ```[1,5]```, while ```torch.Tensor``` returns a ```torch.FloatTensor``` (32-bit by default, otherwise whatever length we have set as default)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc024a23",
   "metadata": {},
   "source": [
    "$$Q = 3a^3 - b^2$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26816e8",
   "metadata": {},
   "source": [
    "**Forward pass**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb9f1d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q = 3*a**3 - b**2\n",
    "Q.is_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17856c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q= tensor([ -6., 339.], grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print('Q=',Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c0daa0",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial Q}{\\partial a} = 9 a^2$$\n",
    "$$\\frac{\\partial Q}{\\partial b} = -2b$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690dda18",
   "metadata": {},
   "source": [
    "```Q``` will be also be tracked by autograd as it was created by operations on variables with ```requires_grad = True```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "068f221f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "704feaaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.is_leaf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef95ea3e",
   "metadata": {},
   "source": [
    "When a tensor is first created, it becomes a leaf node.\n",
    "\n",
    "Basically, all inputs and weights of a neural network are leaf nodes of the computational graph.\n",
    "\n",
    "When any operation is performed on a tensor, it is not a leaf node anymore.\n",
    "\n",
    "Only leaf Tensors will have their grad populated during a call to backward().\n",
    "https://pytorch.org/docs/stable/generated/torch.Tensor.is_leaf.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fba94a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "l=torch.Tensor([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e0a5016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q.is_leaf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8af7eee",
   "metadata": {},
   "source": [
    "<!-- $$\\frac{\\partial Q}{\\partial a} = \\frac{dQ}{dQ}  \\frac{\\partial Q}{\\partial a}$$ -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53a6507",
   "metadata": {},
   "source": [
    "When we call the method ```backward()``` on ```Q```, autograd calculates these gradients and stores them in the respective tensors’ ```.grad``` attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21400202",
   "metadata": {},
   "source": [
    "**Backward pass**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c363fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dQ_dQ = torch.tensor([1.,1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5b1ab72",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q.backward(gradient=dQ_dQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2c15c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  9., 225.])\n",
      "tensor([ -6., -12.])\n"
     ]
    }
   ],
   "source": [
    "print(a.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64e9a289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True, True])\n",
      "tensor([True, True])\n"
     ]
    }
   ],
   "source": [
    "print(9*a**2 == a.grad)\n",
    "print(-2*b == b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037decaa",
   "metadata": {},
   "source": [
    "**<h2>MNIST handwritten digit classification using neural networks**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c4bfe2",
   "metadata": {},
   "source": [
    "We will now present an example where we train a fully-connected neural network on a popular benchmark dataset: MNIST handwritten digits.\n",
    "\n",
    "The MNIST hadwritten digits dataset consists of 60,000 training examples and 10,000 test examples. Each example comprises a 28×28 image and an associated label from one of 10 classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fb1fa6",
   "metadata": {},
   "source": [
    "**<h3> Importing relevant packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b37a757d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from   torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a413d6d9",
   "metadata": {},
   "source": [
    "**<h3>Load dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557735be",
   "metadata": {},
   "source": [
    "The ```torchvision``` library consists of popular datasets, model architectures, and common image transformations for computer vision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06ae0d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train  = datasets.MNIST(\"./data\", train=True, download=True, transform=transforms.ToTensor())\n",
    "mnist_test   = datasets.MNIST(\"./data\", train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e228b79",
   "metadata": {},
   "source": [
    "We should now have a folder ```./data``` with the ```MNIST``` dataset in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2c99f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AI4SD_ML_Summer_School   MAC_MIGS\t\t t10k-images-idx3-ubyte.gz\r\n",
      " continualai\t\t  MATLAB\t\t t10k-labels-idx1-ubyte.gz\r\n",
      " data\t\t\t  Mech.ntua\t\t train-images-idx3-ubyte.gz\r\n",
      " Deutsch\t\t  ML_MD_software\t train-labels-idx1-ubyte.gz\r\n",
      " diabetes.csv\t\t  mnist.pkl\t\t various\r\n",
      "'docs&certificates'\t  Photos_Kat\r\n",
      " GitHub\t\t\t  pytorch_basics.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bda4d0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchvision.datasets.mnist.MNIST'>\n",
      "60000\n",
      "10000\n",
      "<class 'tuple'>\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(type(mnist_train))\n",
    "print(len(mnist_train))\n",
    "print(len(mnist_test))\n",
    "\n",
    "print(type(mnist_train[0]))\n",
    "print(len(mnist_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40894314",
   "metadata": {},
   "source": [
    "```mnist_train[0])``` is a tuple, whose first element is the image tensor representation and the second element is the label of the image (0 to 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96de8e86",
   "metadata": {},
   "source": [
    "Let's see what the first image in our training set looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ffb9177f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f73874f1250>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMkAAADICAYAAABCmsWgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAPYUlEQVR4nO3df3DT530H8Lfwjy+2K4t61JJ1OERLzeBwRoZxHFzAyq1WS69cXLKMhl6OsNsdP2waz9korndDzVGbkp2PNPzIhaU2u5sDl54DbMcydAUEzCELrgnMXp2lMeAVC8/8kBQD/iE/+4NYnXi++LFsCUnm/br7/uGPHsufh+Ttx9+vvj8MQggBInqgabFugCjeMSRECgwJkQJDQqTAkBApMCRECgwJkQJDQqTAkBApMCRECsnReuM9e/bg9ddfR09PD+bPn4+dO3di6dKlyu8bGRnB1atXYTQaYTAYotUePeKEEPD7/bBarZg2TbFWiCg4cOCASElJEfv27RMdHR3ilVdeERkZGeLy5cvK7+3u7hYAuHF7KFt3d7fy/0mDEJE/wbGoqAgLFy7E3r17g7V58+ahrKwMdXV1Y36v1+vFjBkzsATfQTJSIt0aEQBgGEM4g6O4desWTCbTmGMj/ufW4OAgWltbsWXLlpC6w+FAS0uLNH5gYAADAwPBr/1+/5eNpSDZwJBQlHy5NIznT/qI77j39fUhEAjAbDaH1M1mMzwejzS+rq4OJpMpuOXm5ka6JaJJidrRrfsTKoTQTW11dTW8Xm9w6+7ujlZLRBMS8T+3Zs6ciaSkJGnV6O3tlVYXANA0DZqmRboNooiJ+EqSmpqKgoICuFyukLrL5UJxcXGkfxxR1EXlc5Kqqiq89NJLWLRoERYvXoy3334bV65cwfr166Px44iiKiohWbVqFa5fv47XXnsNPT09yM/Px9GjRzF79uxo/DiiqIrK5yST4fP5YDKZYMdzPARMUTMshnASh+H1epGZmTnmWJ67RaTAkBApMCRECgwJkQJDQqTAkBApMCRECgwJkQJDQqTAkBApMCRECgwJkQJDQqTAkBApMCRECgwJkQJDQqQQtXsB0+QZkuX/PElfmznp9+3868elWiB9RHfs7Cd6pVr6Rv0bunnqU6Xarxcd1B3bF+iXakXvvao79utVZ3XrDwtXEiIFhoRIgSEhUmBIiBQYEiIFHt2KgKR5eVJNaPr3DLtaMkOq3XlGPtIDAFkmuX56gf7Romj519tGqfazXd/WHfvRk01SrWvoju7Y7ddKpZr1dFzdAi6IKwmRAkNCpMCQECkwJEQK3HEPQ8C+ULde37hbqs1JkU/RiGdDIqBb/7s3X5Zqyf36O9iL36uQasbfDeuO1frkHfr0cx+N0WHscCUhUmBIiBQYEiIFhoRIgSEhUuDRrTBonVd16613c6XanJRr0W4nxKs9z0i1z7/Qv0Cr8YlfSjXviP4RK/PPWybX2APE5wko+riSECkwJEQKDAmRAkNCpMAd9zAM93h062/+7AWp9tNv618jknThK1Ltk41vjruHbX1/rFv/7JvpUi1wq0d37OrFG6XapR/q/zwbPhl3b1MVVxIiBYaESIEhIVJgSIgUwg7JqVOnsGLFClitVhgMBhw6dCjkdSEEnE4nrFYr0tLSYLfb0d7eHql+iR66sI9u9ff3Y8GCBVi7di2ef/556fUdO3agvr4ejY2NmDNnDrZt24bS0lJ0dnbCaJTvvDEVZDV8KNW+9s9/oDs2cP2GVJuf/xe6Y9uX/UKqHXm7RHds9q3xnz5i+FA+YmWTp0BfCjsky5cvx/Lly3VfE0Jg586dqKmpwcqVKwEA+/fvh9lsRlNTE9atWze5boliIKL7JF1dXfB4PHA4HMGapmkoKSlBS4v+b7qBgQH4fL6QjSieRDQkHs+9D9vMZnNI3Ww2B1+7X11dHUwmU3DLzZXPqCWKpagc3TIYQp9fIYSQaqOqq6vh9XqDW3d3dzRaIpqwiJ6WYrFYANxbUXJycoL13t5eaXUZpWkaNE2LZBtxIdB3fdxjh3zjv7PK/B906Nb/d2+SXBzRvwMKhSeiK4nNZoPFYoHL5QrWBgcH4Xa7UVxcHMkfRfTQhL2SfPHFF/jss8+CX3d1deH8+fPIysrCY489hsrKStTW1iIvLw95eXmora1Feno6Vq9eHdHGiR6WsENy7tw5PPvss8Gvq6qqAABr1qxBY2MjNm/ejDt37mDjxo24efMmioqKcOzYsSn7GQlNfWGHxG63Q4gHX6FsMBjgdDrhdDon0xdR3OC5W0QKvOgqDsz70ae69bVP/qlUa5j9K92xJS+USzXjwdg+2nmq4EpCpMCQECkwJEQKDAmRAnfc40Dglle3fn3DPKl25Yj+02y3bPtHqVb959/THSvaTFIt96cPuKBkjMP9jwquJEQKDAmRAkNCpMCQECkwJEQKPLoVx0Y++S+p9v2f/I3u2H/a+vdS7fwz8hEvAID8vB/Mz5AfLw0Aefvk+wkPf35J/32nKK4kRAoMCZECQ0KkwJAQKRjEWJcZxoDP54PJZIIdzyHZkBLrdhKG+MZTUi1z+//ojn33D/9t3O8798RfSrU/+on+aTSB//583O8ba8NiCCdxGF6vF5mZmWOO5UpCpMCQECkwJEQKDAmRAkNCpMDTUqYIw7+fl2q3/yxbd2zhqk1S7aMfvaE79jfP/oNU+8HjDp2RgHfJGA0mMK4kRAoMCZECQ0KkwJAQKXDHfQoLXOvVrZt/Ltfvbh7WHZtukB8wtO/xf9Ed+93vVcrf//5HY3SYGLiSECkwJEQKDAmRAkNCpMCQECnw6NYUMbLkKan22xem647Nf+qSVNM7ivUgb974E916+uFz436PRMKVhEiBISFSYEiIFBgSIgXuuMcxw6J8qfbpD/V3sPd9Y79UWzZ9cNI9DIghqXb2hk1/8Ih8S9SpgCsJkQJDQqTAkBApMCRECmGFpK6uDoWFhTAajcjOzkZZWRk6OztDxggh4HQ6YbVakZaWBrvdjvb29og2TfQwhXV0y+12o7y8HIWFhRgeHkZNTQ0cDgc6OjqQkZEBANixYwfq6+vR2NiIOXPmYNu2bSgtLUVnZyeMRmNUJpFIkm2zpdpv11p1xzpXHZBqz3+lL+I9AcCPry3SrbvfkJ/489X9D3ic9RQVVkg++OCDkK8bGhqQnZ2N1tZWLFu2DEII7Ny5EzU1NVi5ciUAYP/+/TCbzWhqasK6desi1znRQzKpfRKv997dxbOysgAAXV1d8Hg8cDh+f18mTdNQUlKClpYW3fcYGBiAz+cL2YjiyYRDIoRAVVUVlixZgvz8ex96eTweAIDZbA4Zazabg6/dr66uDiaTKbjl5uZOtCWiqJhwSCoqKnDhwgW8++670msGgyHkayGEVBtVXV0Nr9cb3Lq7uyfaElFUTOi0lE2bNuHIkSM4deoUZs2aFaxbLBYA91aUnJycYL23t1daXUZpmgZN0ybSRtxIfvwxqeYtyNEZCax67QOptn5Gc8R7AoBXe3Qeswvgwz3yTnpW43/ojv3qyKO1k64nrJVECIGKigo0Nzfj+PHjsNlCz+Gx2WywWCxwuVzB2uDgINxuN4qLiyPTMdFDFtZKUl5ejqamJhw+fBhGozG4n2EymZCWlgaDwYDKykrU1tYiLy8PeXl5qK2tRXp6OlavXh2VCRBFW1gh2bt3LwDAbreH1BsaGvDyyy8DADZv3ow7d+5g48aNuHnzJoqKinDs2DF+RkIJK6yQjOcZpAaDAU6nE06nc6I9EcUVnrtFpMCLrh4gOcci1W78IkN37AabW6q9aLwW8Z4AoOJ3+k/K+fXep6TazF/+p+7YLD+PWIWDKwmRAkNCpMCQECkwJEQKj9SO++C35NMxBv/qhu7YH3/9qFRzpPVHvCcAuBa4o1tfduRVqTb3b3+jOzbrlrwzPjK5tuhLXEmIFBgSIgWGhEiBISFSYEiIFB6po1uXyuTfCZ8++d6k33f3rSek2htuh85IwBCQr9Ccu61Ld2zeNfnxzoEwe6PJ40pCpMCQECkwJEQKDAmRgkGM53LDh8jn88FkMsGO55BsSIl1OzRFDYshnMRheL1eZGZmjjmWKwmRAkNCpMCQECkwJEQKDAmRAkNCpMCQECkwJEQKDAmRAkNCpMCQECkwJEQKDAmRAkNCpMCQECnE3Y0gRi9vGcYQEFdXutBUMowhAON7elvchcTv9wMAzkC+Fy9RpPn9fphMpjHHxN2ViSMjI7h69SqMRiP8fj9yc3PR3d2tvHos0fh8Ps4thoQQ8Pv9sFqtmDZt7L2OuFtJpk2bhlmzZgG495BSAMjMzIzbf+zJ4txiR7WCjOKOO5ECQ0KkENch0TQNW7duhaZpsW4l4ji3xBF3O+5E8SauVxKieMCQECkwJEQKDAmRQlyHZM+ePbDZbJg+fToKCgpw+vTpWLcUtlOnTmHFihWwWq0wGAw4dOhQyOtCCDidTlitVqSlpcFut6O9vT02zYahrq4OhYWFMBqNyM7ORllZGTo7O0PGJOrc7he3ITl48CAqKytRU1ODtrY2LF26FMuXL8eVK1di3VpY+vv7sWDBAuzatUv39R07dqC+vh67du3Cxx9/DIvFgtLS0uA5bPHK7XajvLwcZ8+ehcvlwvDwMBwOB/r7f/+s+0Sdm0TEqaefflqsX78+pDZ37lyxZcuWGHU0eQDE+++/H/x6ZGREWCwWsX379mDt7t27wmQyibfeeisGHU5cb2+vACDcbrcQYmrNLS5XksHBQbS2tsLhCH3uoMPhQEtLS4y6iryuri54PJ6QeWqahpKSkoSbp9frBQBkZWUBmFpzi8uQ9PX1IRAIwGw2h9TNZjM8Hk+Muoq80bkk+jyFEKiqqsKSJUuQn58PYOrMDYjDs4D/v9GzgEcJIaTaVJDo86yoqMCFCxdw5swZ6bVEnxsQpyvJzJkzkZSUJP3G6e3tlX4zJTKLxQIACT3PTZs24ciRIzhx4kTwEgdgasxtVFyGJDU1FQUFBXC5XCF1l8uF4uLiGHUVeTabDRaLJWSeg4ODcLvdcT9PIQQqKirQ3NyM48ePw2azhbyeyHOTxPSwwRgOHDggUlJSxDvvvCM6OjpEZWWlyMjIEJcuXYp1a2Hx+/2ira1NtLW1CQCivr5etLW1icuXLwshhNi+fbswmUyiublZXLx4Ubz44osiJydH+Hy+GHc+tg0bNgiTySROnjwpenp6gtvt27eDYxJ1bveL25AIIcTu3bvF7NmzRWpqqli4cGHw8GIiOXHihMC9W1qEbGvWrBFC3DtUunXrVmGxWISmaWLZsmXi4sWLsW16HPTmBEA0NDQExyTq3O7HU+WJFOJyn4QonjAkRAoMCZECQ0KkwJAQKTAkRAoMCZECQ0KkwJAQKTAkRAoMCZECQ0Kk8H+1XSOYJmPhOQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (2,2)                # set figure size\n",
    "plt.imshow(mnist_train[0][0].view(28,28))             # show image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9ecb35",
   "metadata": {},
   "source": [
    "**<h3> Dataloader class**\n",
    "    \n",
    "https://pytorch.org/docs/stable/data.html#map-style-datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f955aa",
   "metadata": {},
   "source": [
    "At the heart of ```PyTorch``` data loading utility is the ```torch.utils.data.DataLoader``` class. It represents a Python iterable over a dataset\n",
    "\n",
    "```python\n",
    "DataLoader(dataset, batch_size=1, shuffle=False, \n",
    "           sampler=None,batch_sampler=None, num_workers=0,\n",
    "           collate_fn=None,pin_memory=False, drop_last=False, \n",
    "           timeout=0, worker_init_fn=None, *, prefetch_factor=2,\n",
    "           persistent_workers=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d96636f",
   "metadata": {},
   "source": [
    "The most important argument of ```DataLoader``` constructor is ```dataset```, which indicates a dataset object to load data from. PyTorch supports two different types of datasets:\n",
    "\n",
    "- Map style datasets: Datasets that implement the ```__getitem__()``` and ```__len__()``` methods and are maps from keys to data samples.\n",
    "\n",
    "- Iterable style datasets: When reading from a stream of data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c3d9dcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(mnist_train)\n",
    "# mnist_train.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3106bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train  =  DataLoader(mnist_train, batch_size=len(mnist_train), shuffle=True)\n",
    "dataloader_test   =  DataLoader(mnist_test, batch_size=len(mnist_test), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "47acbdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape train and test images from 28x28 to 1x784\n",
    "for i,data in enumerate(dataloader_train):\n",
    "    xtrain      = data[0].view(-1,784)       # torch.Tensor.view() is equivalent to reshape\n",
    "    ytrain      = data[1]                    # train labels\n",
    "\n",
    "for i,data in enumerate(dataloader_test):      \n",
    "    xtest        = data[0].view(-1,784)     # test images, The size -1 is inferred from other dimensions\n",
    "    xtest_conv   = data[0]                  # we ll use these non-flattened images for testing the convolutional net\n",
    "    ytest=data[1]                           # test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "45b654ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_mnist_train       = TensorDataset(xtrain, ytrain)\n",
    "flat_dataloader_train  =  DataLoader(flat_mnist_train, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af0faaaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 784])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(xtrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fee349",
   "metadata": {},
   "source": [
    "**<h3>Defining the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5decffcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "555148b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_net(nn.Module):    # this class inherits from nn.Module\n",
    "    def __init__(self):\n",
    "        super(Neural_net, self).__init__() #this calls the constructor of the parent class nn.Module\n",
    "        \n",
    "        # define network layers\n",
    "        self.fc1 = nn.Linear(784, 400)   # nn.Linear is a class for linear layers (16,12) are the constructor arguments\n",
    "        self.fc2 = nn.Linear(400, 400)\n",
    "        self.fc3 = nn.Linear(400, 400)\n",
    "        self.fc4 = nn.Linear(400, 10)\n",
    "        torch.manual_seed(4)           # generating numbers changes the state of the random number generator.\n",
    "                                       # we thus have to set the seed back to 2  \n",
    "#         self.initialize_weights()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = torch.relu(self.fc1(x))  # https://discuss.pytorch.org/t/what-is-the-difference-between-torch-relu-torch-nn-relu-and-torch-nn-functional-relu/91101/2\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "    \n",
    "#     def initialize_weights(self):\n",
    "#         for m in self.modules():\n",
    "#             if isinstance(m,nn.Linear):\n",
    "#                 nn.init.kaiming_normal_(m.weight)\n",
    "#                 nn.init.constant_(m.bias,0.0)\n",
    "    \n",
    "# nn.ReLU() creates an nn.Module which you can add e.g. to an nn.Sequential model.\n",
    "# nn.functional.relu on the other side is just the functional API call to the relu function, so that you can add \n",
    "# it e.g. in your forward method yourself.\n",
    "\n",
    "# Generally speaking it might depend on your coding style if you prefer modules for the activations or the \n",
    "# functional calls. Personally I prefer the module approach if the activation has an internal state, e.g. PReLU.\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6f452c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Neural_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8644d743",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_accuracy(output,y):\n",
    "    '''If np.argmax(out,axis=1)-y is non-zero, i.e. label y is 9 and prediction is 5 then \n",
    "       diff is incremented by 1, i.e. every time there is a mismatch between prediction and label.\n",
    "       The ratio diff/np.size(y) gives us the ratio of false predictions over the total number of datapoints.\n",
    "       One minus that gives the model accuracy.\n",
    "       '''\n",
    "    # we can't call numpy() on Tensors that requires grad. So, in order to compute diff (see below)\n",
    "    # we need to use tensor.detach().numpy()\n",
    "    output = output.cpu().detach().numpy()    # no need for the .cpu() here as we are working with cpu tensors\n",
    "    y      = y.cpu().detach().numpy()\n",
    "    diff   = np.count_nonzero(np.argmax(output,axis=1)-y) # np.argmax returns the index/indices of max value(s)\n",
    "                                                        # along specified axis\n",
    "    return (1-(diff/np.size(y)))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039aca31",
   "metadata": {},
   "source": [
    "**<h3> Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8bd67598",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff51795",
   "metadata": {},
   "source": [
    "Cross entropy loss (https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss):\n",
    "\n",
    "$$H(p,q) =  –\\sum_{x \\in \\mathcal{X}} p(x)  \\log(q(x))$$\n",
    "\n",
    "For binary classification\n",
    "\n",
    "$$loss=−(y \\log(p)+(1−y) \\log(1−p))$$\n",
    "\n",
    "So, if ```y=1``` and ```p=1``` then $loss = - 1 \\log(1) = 0$\n",
    "\n",
    "and if ```y=1``` and ```p=0``` then $loss = -1 \\log(0)=+ \\infty$\n",
    "\n",
    "Similarly, if ```y=0``` and ```p=0``` then $loss = - (1-0) \\log(1-0) = 0$\n",
    "\n",
    "and if ```y=0``` and ```p=1``` then $loss = - (1-0) \\log(1-1) = +\\infty$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1bda2b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neural_net(\n",
       "  (fc1): Linear(in_features=784, out_features=400, bias=True)\n",
       "  (fc2): Linear(in_features=400, out_features=400, bias=True)\n",
       "  (fc3): Linear(in_features=400, out_features=400, bias=True)\n",
       "  (fc4): Linear(in_features=400, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b53ea5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for p in net.parameters():\n",
    "    print(p.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7c48c511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for n,p in net.named_parameters():\n",
    "#     print(n)\n",
    "#     print(p.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6aedfb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0/1, accuracy train 9.38 %, loss train, 2.30534, accuracy test 9.81 %, loss test, 2.30254\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=5*10**-3, momentum=0.9)\n",
    "\n",
    "for epoch in range(num_epochs): \n",
    "    for i,data in enumerate(flat_dataloader_train):\n",
    "        # Load in the training datapoints\n",
    "        x=data[0]                  # equivalent to torch.float64\n",
    "        y=data[1]   \n",
    "        optimizer.zero_grad()\n",
    "        output = net(x)\n",
    "        loss = criterion(output,y) \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "                   \n",
    "        if epoch % 1 == 0 and i==0:\n",
    "            # evety 100 epochs after the first batch \n",
    "            acc        = class_accuracy(output,y)\n",
    "            outputtest = net(xtest)\n",
    "            loss_test  = criterion(outputtest,ytest)\n",
    "            acc_test   = class_accuracy(outputtest,ytest)\n",
    "            print(f'epoch {epoch}/{num_epochs}, accuracy train {acc:.2f} %, loss train, {loss.item():.5f}, accuracy test {acc_test:.2f} %, loss test, {loss_test.item():.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d7050f",
   "metadata": {},
   "source": [
    "**<h3>Alternative model: Convolutional neural network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a54d333d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train  =  DataLoader(mnist_train, batch_size=256, shuffle=True)\n",
    "dataloader_test   =  DataLoader(mnist_test, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f73e3503",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)  # nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()              # Randomly zero out entire channels of the input tenor\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bba4f0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0/5, accuracy train 13.67 %, lost train, 2.29797, accuracy test 12.38 %, lost test, 2.30212\n",
      "epoch 1/5, accuracy train 82.03 %, lost train, 0.53316, accuracy test 81.83 %, lost test, 0.58233\n",
      "epoch 2/5, accuracy train 83.20 %, lost train, 0.58118, accuracy test 87.35 %, lost test, 0.41130\n",
      "epoch 3/5, accuracy train 89.06 %, lost train, 0.32455, accuracy test 90.40 %, lost test, 0.32772\n",
      "epoch 4/5, accuracy train 90.23 %, lost train, 0.27760, accuracy test 91.45 %, lost test, 0.28107\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "for epoch in range(num_epochs): \n",
    "    for i,data in enumerate(dataloader_train):\n",
    "        # Load in the training datapoints\n",
    "        x=data[0]                  # equivalent to torch.float64\n",
    "        y=data[1].long()   \n",
    "        optimizer.zero_grad()\n",
    "        output = model(x.double())\n",
    "        loss = criterion(output,y) \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "                   \n",
    "        if (epoch) % 1 == 0 and i==0:\n",
    "            # evety 100 epochs after the first batch \n",
    "            acc        = class_accuracy(output,y)\n",
    "            outputtest = model(xtest_conv)\n",
    "            loss_test  = criterion(outputtest,ytest)\n",
    "            acc_test   = class_accuracy(outputtest,ytest)\n",
    "            print(f'epoch {epoch}/{num_epochs}, accuracy train {acc:.2f} %, lost train, {loss.item():.5f}, accuracy test {acc_test:.2f} %, lost test, {loss_test.item():.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80fa448",
   "metadata": {},
   "source": [
    "**<h3> Pima Indians diabetes dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5820425f",
   "metadata": {},
   "source": [
    "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases (United States). The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage. https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7466066a",
   "metadata": {},
   "source": [
    "We will use ```pandas``` to load the dataset. Pandas is an open source Python package that is most widely used for data science/data analysis and machine learning tasks. It is built on top of the ```numpy``` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b193075b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install -c anaconda pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d2b6d27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b03d128c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./diabetes.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aefc95c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cac4842",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/aadhilimam/pima-diabetes-classification-using-pytorch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
